{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on Bag of Words, creating a Vocab of all possible unique words across all documents\n",
    "- A document is represented by a feature vector with integer elements whose value is the frequency of that word in the document.\n",
    "- Mostly used for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Building from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`To Build a text classifier based on a collection of few documents each having a small corpus of SMS data under three classes: Spam, Ham and to pedict the class of a new document.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is a collection of documents each containing a huge set of SMS data. Label, Document and DocNumber are the fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document Label\n",
       "0           1  Go until jurong point, crazy.. Available only ...   ham\n",
       "1           2                      Ok lar... Joking wif u oni...   ham\n",
       "2           3  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3           4  U dun say so early hor... U c already then say...   ham\n",
       "4           5  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data//data_5_3_Spam_Ham_Dataset_BinaryClass.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labelling Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'ham': 0, u'spam': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label\n",
       "0           1  Go until jurong point, crazy.. Available only ...      0\n",
       "1           2                      Ok lar... Joking wif u oni...      0\n",
       "2           3  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3           4  U dun say so early hor... U c already then say...      0\n",
       "4           5  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_target, id_target = {}, 0\n",
    "\n",
    "for key in df.Label.unique():\n",
    "    dict_target[key] = id_target\n",
    "    id_target += 1\n",
    "\n",
    "print dict_target\n",
    "    \n",
    "df.Label = df.Label.map(dict_target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(document_column):\n",
    "    \n",
    "    # Convert unicode to string\n",
    "    document_column = document_column.apply(lambda x: x.encode('ascii', 'ignore') if type(x) == unicode else x)\n",
    "    \n",
    "    # Loading Stop_Words, Stop_Letters test file\n",
    "    StopWords_txt = open('Data/Stop_Words.txt', 'r').read()\n",
    "    stop_words = re.findall(\"\\'(\\w+)\\'\",StopWords_txt)\n",
    "    stop_letters = re.findall(r'\\w', string.letters)\n",
    "    \n",
    "    # Loading NLTK's leammatizer-> Example: 'plays' is converted to 'play'\n",
    "    lm = WordNetLemmatizer()\n",
    "    \n",
    "    processed_documents = []\n",
    "    for doc in document_column:\n",
    "        \n",
    "        doc = str(doc)\n",
    "        doc_words, final_doc_words = [], []        \n",
    "            \n",
    "        # Basic regex\n",
    "        doc = re.sub('[\\s\\t\\n\\r\\.\\{\\(\\[\\}\\]\\)\\,\\;\\'\\\"\\/\\\\\\?\\_\\-\\>\\<\\\\:\\-\\+\\=\\@\\#\\$\\%\\&\\*\\!0-9]+', ' ', doc)\n",
    "        doc = re.sub('\\s+', ' ', doc)\n",
    "        doc = ' '.join(re.findall('\\w+', doc))\n",
    "        doc = str(doc.lower())\n",
    "        \n",
    "        # Stop words, Stop letters\n",
    "        for w in doc.split():\n",
    "            if w not in stop_words and w not in stop_letters:\n",
    "                doc_words.append(w)    \n",
    "                \n",
    "        # Lematize\n",
    "        for w in doc_words:\n",
    "            final_doc_words.append(str(lm.lemmatize(w)))\n",
    "        \n",
    "        # Appending to a final list\n",
    "        processed_documents.append(' '.join(final_doc_words))\n",
    "        \n",
    "    return processed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5496</td>\n",
       "      <td>Good afternoon, my love ... How goes your day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>good afternoon love go day sleep hope well boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5370</td>\n",
       "      <td>Hi mom we might be back later than  &amp;lt;#&amp;gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>hi mom might back later lt gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3815</td>\n",
       "      <td>Pls i wont belive god.not only jesus.</td>\n",
       "      <td>0</td>\n",
       "      <td>pls wont belive god jesus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2234</td>\n",
       "      <td>Nothing just getting msgs by dis name wit diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>nothing getting msg dis name wit different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4559</td>\n",
       "      <td>I am in hospital da. . I will return home in e...</td>\n",
       "      <td>0</td>\n",
       "      <td>hospital da return home evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label  \\\n",
       "0        5496  Good afternoon, my love ... How goes your day ...      0   \n",
       "1        5370     Hi mom we might be back later than  &lt;#&gt;       0   \n",
       "2        3815              Pls i wont belive god.not only jesus.      0   \n",
       "3        2234  Nothing just getting msgs by dis name wit diff...      0   \n",
       "4        4559  I am in hospital da. . I will return home in e...      0   \n",
       "\n",
       "                                  Processed_Document  \n",
       "0  good afternoon love go day sleep hope well boy...  \n",
       "1                      hi mom might back later lt gt  \n",
       "2                          pls wont belive god jesus  \n",
       "3         nothing getting msg dis name wit different  \n",
       "4                    hospital da return home evening  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_Document'] = preprocessing(df.Document)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>Update_Now - Xmas Offer! Latest Motorola, Sony...</td>\n",
       "      <td>1</td>\n",
       "      <td>update xmas offer latest motorola sonyericsson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2449</td>\n",
       "      <td>Tmr then Ã¼ brin lar... Aiya later i come n c ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tmr brin lar aiya later come lar mayb neva set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1893</td>\n",
       "      <td>Probably earlier than that if the station's wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>probably earlier station think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1705</td>\n",
       "      <td>Just taste fish curry :-P</td>\n",
       "      <td>0</td>\n",
       "      <td>taste fish curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2534</td>\n",
       "      <td>Yup ok...</td>\n",
       "      <td>0</td>\n",
       "      <td>yup ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label  \\\n",
       "0         368  Update_Now - Xmas Offer! Latest Motorola, Sony...      1   \n",
       "1        2449  Tmr then Ã¼ brin lar... Aiya later i come n c ...      0   \n",
       "2        1893  Probably earlier than that if the station's wh...      0   \n",
       "3        1705                          Just taste fish curry :-P      0   \n",
       "4        2534                                          Yup ok...      0   \n",
       "\n",
       "                                  Processed_Document  \n",
       "0  update xmas offer latest motorola sonyericsson...  \n",
       "1  tmr brin lar aiya later come lar mayb neva set...  \n",
       "2                     probably earlier station think  \n",
       "3                                   taste fish curry  \n",
       "4                                             yup ok  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size):\n",
    "    \n",
    "    train_index = int(train_size*len(df))\n",
    "    test_index = train_index + 1\n",
    "    \n",
    "    train_data = df[0:train_index+1]\n",
    "    test_data = df[test_index:]\n",
    "    print \"-> train data = {} Rows;  test data = {} Rows\".format(len(train_data), len(test_data))\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> train data = 4458 Rows;  test data = 1114 Rows\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Vocabulary using _ONLY _  \"Training Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (Train Data)= 6305 words\n"
     ]
    }
   ],
   "source": [
    "# This is a very crude and generalised way\n",
    "Vocab = sorted(list(set(' '.join(train_data.Processed_Document).split())))\n",
    "\n",
    "print \"Vocabulary (Train Data)= {} words\".format(len(Vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in Dataset = 7116 words\n"
     ]
    }
   ],
   "source": [
    "print \"Total Words in Dataset = {} words\".format(len(sorted(list(set(' '.join(df.Processed_Document).split())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaooooright</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aathi</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbey</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomen</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abeg</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aberdeen</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1  0\n",
       "aa           0  1\n",
       "aah          0  3\n",
       "aaooooright  0  1\n",
       "aathi        0  3\n",
       "ab           1  0\n",
       "abbey        0  1\n",
       "abdomen      0  1\n",
       "abeg         0  1\n",
       "abel         0  1\n",
       "aberdeen     1  0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frequency_table = pd.DataFrame(index=Vocab)\n",
    "\n",
    "for cls in train_data.Label.unique():\n",
    "    \n",
    "    col_name = cls\n",
    "    \n",
    "    perClass_all_doc_words = pd.Series(' '.join(train_data[train_data.Label == cls]['Processed_Document']).split())\n",
    "    perClass_all_term_frequency = perClass_all_doc_words.value_counts()\n",
    "    \n",
    "    perClass_term_freq = []\n",
    "    for w in Frequency_table.index:\n",
    "        if w in perClass_all_term_frequency.index:            \n",
    "            perClass_term_freq.append(perClass_all_term_frequency[w])\n",
    "        else:\n",
    "            perClass_term_freq.append(0)\n",
    "            \n",
    "    Frequency_table[col_name] = perClass_term_freq\n",
    "\n",
    "Frequency_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Represnts all the words in the index axis along with their frequencies per class 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prob of a class: P(Class = C_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_class(cls):\n",
    "    P = train_data.Label.value_counts()[cls].astype(float)/train_data.Label.value_counts().sum()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prob of  a word given a particular class: P(Wordj |Class = C_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P(Wordj | Class=C_i) = [ n(Wordj) when class=C_i + alpha ] / [n(Total words) where class=C_i + len(Vocab)]\n",
    "# alpha -> Smoothing Fucntion Parameter\n",
    "#        - That if number of W1 words under Class C1 is equal to 0, it might make the entire P = 0, as P = P(W1)xP(W2)...\n",
    "#        - Also we are not ignoring the chances of this word even if it didn't occur in this class, by giving it a less Prob.\n",
    "#        - Alpha should be small value, so that we are giving it a less Prob.\n",
    "#        - Dividing by Vocab to normailize\n",
    "\n",
    "def prob_word_given_class(word, cls, alpha):\n",
    "    P = (Frequency_table[Frequency_table.index == word][cls].values[0].astype(float) + alpha) /(Frequency_table[cls].sum() + len(Vocab))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood: Prob of a unknown class given all words in the test data: P(Class=? | W1,W2,W3,W4...... Wj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_class_with_test_feature_vector(test_doc):\n",
    "    \n",
    "    global Vocab\n",
    "    \n",
    "    # Intilising \"big_class\" with a random choice\n",
    "    big = 0\n",
    "    big_class = random.choice(df.Label.unique())\n",
    "\n",
    "    # Smoothing Function Parameter \n",
    "    alpha = 0.0001\n",
    "\n",
    "    for cls in df.Label.unique():\n",
    "        \n",
    "        # Bayes Rule: P(X|Y) = P(Y|X) * P(X) / P(Y)\n",
    "        # Applying & ignoring the denominator, as it will be a same value.\n",
    "        # likelihhod P(Class=C1|W1,W2,...,Wj) = P(W1, W2..., Wj) * P(Class=C1) = P(W1|C1)*P(W2|C1)* ...*P(Wj|C1) * P(C1)\n",
    "        # likelihhod P(Class=C2|W1,W2,...,Wj) = P(W1, W2..., Wj) * P(Class=C2) = P(W1|C2)*P(W2|C2)* ...*P(Wj|C2) * P(C2)\n",
    "        # ...\n",
    "        # likelihhod P(Class=Ck|W1,W2,...,Wj) = P(W1, W2..., Wj) * P(Class=Ck) = P(W1|Ck)*P(W2|Ck)* ...*P(Wj|Ck) * P(Ck)\n",
    "        \n",
    "        likelihood = 1\n",
    "        for word in test_doc.split():  \n",
    "            \n",
    "            # Checking if there's a new word in new data which was not even present in the Vocab \n",
    "            # Example: For a newer word which was not in train or test data either...\n",
    "            if word in Vocab:\n",
    "                likelihood *= prob_word_given_class(word, cls, alpha)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        likelihood *= prob_class(cls)\n",
    "\n",
    "        if likelihood > big:\n",
    "            big = likelihood\n",
    "            big_class = cls\n",
    "\n",
    "    return big_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat = []\n",
    "\n",
    "for test_doc in test_data['Processed_Document'].astype(str):\n",
    "\n",
    "    predicted_class = prob_class_with_test_feature_vector(test_doc)\n",
    "    Y_test_hat.append(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Y_test</th>\n",
       "      <th>Y_test_hat (predicted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score  Y_test  Y_test_hat (predicted)\n",
       "4458    100       0                       0\n",
       "4459    100       0                       0\n",
       "4460    100       0                       0\n",
       "4461    100       0                       0\n",
       "4462    100       0                       0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(len(test_data)):\n",
    "\n",
    "    if list(test_data.Label)[i] == Y_test_hat[i]:\n",
    "        score.append(100)\n",
    "    else:\n",
    "        score.append(0)\n",
    "        \n",
    "accuracy_matrix = pd.DataFrame({'Y_test': test_data.Label, \n",
    "                                'Y_test_hat (predicted)': Y_test_hat,\n",
    "                                'Score': score })\n",
    "accuracy_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of model = 97.8456014363%\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy Score of model = {}%\".format(accuracy_matrix.Score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Using Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>Update_Now - Xmas Offer! Latest Motorola, Sony...</td>\n",
       "      <td>1</td>\n",
       "      <td>update xmas offer latest motorola sonyericsson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2449</td>\n",
       "      <td>Tmr then Ã¼ brin lar... Aiya later i come n c ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tmr brin lar aiya later come lar mayb neva set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1893</td>\n",
       "      <td>Probably earlier than that if the station's wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>probably earlier station think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1705</td>\n",
       "      <td>Just taste fish curry :-P</td>\n",
       "      <td>0</td>\n",
       "      <td>taste fish curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2534</td>\n",
       "      <td>Yup ok...</td>\n",
       "      <td>0</td>\n",
       "      <td>yup ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label  \\\n",
       "0         368  Update_Now - Xmas Offer! Latest Motorola, Sony...      1   \n",
       "1        2449  Tmr then Ã¼ brin lar... Aiya later i come n c ...      0   \n",
       "2        1893  Probably earlier than that if the station's wh...      0   \n",
       "3        1705                          Just taste fish curry :-P      0   \n",
       "4        2534                                          Yup ok...      0   \n",
       "\n",
       "                                  Processed_Document  \n",
       "0  update xmas offer latest motorola sonyericsson...  \n",
       "1  tmr brin lar aiya later come lar mayb neva set...  \n",
       "2                     probably earlier station think  \n",
       "3                                   taste fish curry  \n",
       "4                                             yup ok  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.Processed_Document\n",
    "Y = df.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457 4457\n",
      "1115 1115\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=0.80)\n",
    "\n",
    "print len(X_train), len(Y_train)\n",
    "print len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Converts text into a feature vector     Doc            (Term_doc) Hey   May   Be   -->  Feature Vector\n",
    "#                                     \"Hey may be\"                   1     1     1        [1,1,1]\n",
    "#                                     \" may be\"                      0     1     1        [0,1,1]\n",
    "#                                     \" hey hey may be be hey\"       3     1     2        [3,1,2]\n",
    "Vector = CountVectorizer()\n",
    "\n",
    "-> Vecotor.fit_transform()     : fits the data into vectors and then standardizes it.\n",
    "-> Vector.get_feature_names()  : tells about the features created (unique words) or is called a Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Train-data Vocab and vectorising train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab (Train Data) = 6247 words\n"
     ]
    }
   ],
   "source": [
    "# Create a Vector for our train data's vocabulary...\n",
    "Vector = CountVectorizer()\n",
    "\n",
    "# Vector to fit with our training data to create Vocabulary, Vocab Built!\n",
    "Vector.fit(X_train)\n",
    "\n",
    "# Printing length of our train data's Vocab..\n",
    "print 'Vocab (Train Data) = {} words'.format(len(Vector.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform our train data (Vectorising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vector Standardized using transform()\n",
    "X_train_vector = Vector.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = [[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print \"X_train = {}\".format(X_train_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (4457L, 6247L)\n"
     ]
    }
   ],
   "source": [
    "print 'Shape =', X_train_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform test-data (using fitted vocabulary) into a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (1115L, 6247L)\n"
     ]
    }
   ],
   "source": [
    "# Using training data's Vocab (fitted on vector) to transform test sample\n",
    "X_test_vector = Vector.transform(X_test)\n",
    "\n",
    "print \"Shape =\", X_test_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Columns/Features should be same as we have used training-data's Vocab to transform test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vector, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat = model.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.399103139013448"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_test_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
