{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli's Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is based on a boolean value (true or false) or (1 or 0) for presence or absence of a test word in our training data.\n",
    "- Based on Bag of Words, creating a Vocab of all possible unique words across all documents.\n",
    "- A document is represented by a feature vector with integer elements whose value is the presence of that word in the document.\n",
    "- Mostly used for text classification for shorter documents.\n",
    "- Order is not maintained thus sentiment of a sentnece is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Building from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`To Build a text classifier based on a collection of few documents each having a small corpus of SMS data under three classes: Spam, Ham and to pedict the class of a new document.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is a collection of documents each containing a huge set of SMS data. Label, Document and DocNumber are the fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document Label\n",
       "0           1  Go until jurong point, crazy.. Available only ...   ham\n",
       "1           2                      Ok lar... Joking wif u oni...   ham\n",
       "2           3  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3           4  U dun say so early hor... U c already then say...   ham\n",
       "4           5  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data//data_5_3_Spam_Ham_Dataset_BinaryClass.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'ham': 0, u'spam': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label\n",
       "0           1  Go until jurong point, crazy.. Available only ...      0\n",
       "1           2                      Ok lar... Joking wif u oni...      0\n",
       "2           3  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3           4  U dun say so early hor... U c already then say...      0\n",
       "4           5  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_target, id_target = {}, 0\n",
    "\n",
    "for key in df.Label.unique():\n",
    "    dict_target[key] = id_target\n",
    "    id_target += 1\n",
    "\n",
    "print dict_target\n",
    "    \n",
    "df.Label = df.Label.map(dict_target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(document_column):\n",
    "    \n",
    "    # Convert unicode to string\n",
    "    document_column = document_column.apply(lambda x: x.encode('ascii', 'ignore') if type(x) == unicode else x)\n",
    "    \n",
    "    # Loading Stop_Words, Stop_Letters test file\n",
    "    StopWords_txt = open('Data/Stop_Words.txt', 'r').read()\n",
    "    stop_words = re.findall(\"\\'(\\w+)\\'\",StopWords_txt)\n",
    "    stop_letters = re.findall(r'\\w', string.letters)\n",
    "    \n",
    "    # Loading NLTK's leammatizer-> Example: 'plays' is converted to 'play'\n",
    "    lm = WordNetLemmatizer()\n",
    "    \n",
    "    processed_documents = []\n",
    "    for doc in document_column:\n",
    "        \n",
    "        doc = str(doc)\n",
    "        doc_words, final_doc_words = [], []        \n",
    "            \n",
    "        # Basic regex\n",
    "        doc = re.sub('[\\s\\t\\n\\r\\.\\{\\(\\[\\}\\]\\)\\,\\;\\'\\\"\\/\\\\\\?\\_\\-\\>\\<\\\\:\\-\\+\\=\\@\\#\\$\\%\\&\\*\\!0-9]+', ' ', doc)\n",
    "        doc = re.sub('\\s+', ' ', doc)\n",
    "        doc = ' '.join(re.findall('\\w+', doc))\n",
    "        doc = str(doc.lower())\n",
    "        \n",
    "        # Stop words, Stop letters\n",
    "        for w in doc.split():\n",
    "            if w not in stop_words and w not in stop_letters:\n",
    "                doc_words.append(w)    \n",
    "                \n",
    "        # Lematize\n",
    "        for w in doc_words:\n",
    "            final_doc_words.append(str(lm.lemmatize(w)))\n",
    "        \n",
    "        # Appending to a final list\n",
    "        processed_documents.append(' '.join(final_doc_words))\n",
    "        \n",
    "    return processed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazy available bugis great wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>dun say early hor already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label  \\\n",
       "0           1  Go until jurong point, crazy.. Available only ...      0   \n",
       "1           2                      Ok lar... Joking wif u oni...      0   \n",
       "2           3  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3           4  U dun say so early hor... U c already then say...      0   \n",
       "4           5  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                  Processed_Document  \n",
       "0  go jurong point crazy available bugis great wo...  \n",
       "1                              ok lar joking wif oni  \n",
       "2  free entry wkly comp win fa cup final tkts st ...  \n",
       "3                      dun say early hor already say  \n",
       "4                nah think go usf life around though  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_Document'] = preprocessing(df.Document)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4773</td>\n",
       "      <td>Hi..i got the money da:)</td>\n",
       "      <td>0</td>\n",
       "      <td>hi got money da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2981</td>\n",
       "      <td>Xmas Offer! Latest Motorola, SonyEricsson &amp; No...</td>\n",
       "      <td>1</td>\n",
       "      <td>xmas offer latest motorola sonyericsson nokia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4579</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>1</td>\n",
       "      <td>contract mobile mnths latest motorola nokia et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272</td>\n",
       "      <td>Sorry chikku, my cell got some problem thts y ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry chikku cell got problem thts nt able rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3747</td>\n",
       "      <td>Aight, let me know when you're gonna be around...</td>\n",
       "      <td>0</td>\n",
       "      <td>aight let know gonna around usf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label  \\\n",
       "0        4773                           Hi..i got the money da:)      0   \n",
       "1        2981  Xmas Offer! Latest Motorola, SonyEricsson & No...      1   \n",
       "2        4579  Had your contract mobile 11 Mnths? Latest Moto...      1   \n",
       "3        1272  Sorry chikku, my cell got some problem thts y ...      0   \n",
       "4        3747  Aight, let me know when you're gonna be around...      0   \n",
       "\n",
       "                                  Processed_Document  \n",
       "0                                    hi got money da  \n",
       "1  xmas offer latest motorola sonyericsson nokia ...  \n",
       "2  contract mobile mnths latest motorola nokia et...  \n",
       "3  sorry chikku cell got problem thts nt able rep...  \n",
       "4                    aight let know gonna around usf  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size):\n",
    "    \n",
    "    train_index = int(train_size*len(df))\n",
    "    test_index = train_index + 1\n",
    "    \n",
    "    train_data = df[0:train_index+1]\n",
    "    test_data = df[test_index:]\n",
    "    print \"-> train data = {} Rows;  test data = {} Rows\".format(len(train_data), len(test_data))\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> train data = 4458 Rows;  test data = 1114 Rows\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIM: P(Class = ? |W1, W2, W3, W4, W5, ..., Wj) = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: \n",
    "\n",
    "        Bayes Rule: \n",
    "        P(X|Y) = P(Y|X) * P(X) / P(Y)\n",
    "        \n",
    "        Naive Bayes Modified Bayes Theorem:\n",
    "        NB Likelihood P(Class = Y| X1,X2...,Xj) ~= P(X1|Y)*P(X2|Y)* ...*P(Xj|Y) * P(Y)        {Can igonre the denominator}\n",
    "        \n",
    "        Assumption:\n",
    "        All features are conditionally independent.\n",
    "        \n",
    "        \n",
    "        Vocab = [V1, V2, V3, ..., Vn]\n",
    "        \n",
    "        Test Doc:\n",
    "        Words = Presence or absence of words = [V1 = 1 or 0, V2 = 1 or 0,..., Vn=1 or 0] = [1,0,0,1,0....,1]\n",
    "        \n",
    "        Likelihood:\n",
    "        # likelihhod P(Class=C1|W1,W2,...,Wj) = P(W1, W2..., Wj) * P(Class=C1) = P(W1|C1)*P(W2|C1)* ...*P(Wj|C1) * P(C1)\n",
    "        # likelihhod P(Class=C2|W1,W2,...,Wj) = P(W1, W2..., Wj) * P(Class=C2) = P(W1|C2)*P(W2|C2)* ...*P(Wj|C2) * P(C2)\n",
    "        # ...\n",
    "        # likelihhod P(Class=Ck|W1,W2,...,Wj) = P(W1, W2..., Wj) * P(Class=Ck) = P(W1|Ck)*P(W2|Ck)* ...*P(Wj|Ck) * P(Ck)\n",
    "                \n",
    "        And compare which likelihood(P) is greater, that will be the predicted class!\n",
    "        \n",
    "        \n",
    "        Calculations:\n",
    "        \n",
    "        1. P(C1)    =  n(docs) where class = C1 / n(Total Docs)\n",
    "        \n",
    "        2. P(W1=1|C1) =  n(docs where W1 is present where Class = C1) + aplha / n(total docs where Class = c1) + len(Vocab)\n",
    "                    \n",
    "                      Numerator represents the presence of W1 in all docs where class is C1\n",
    "                       \n",
    "                   alpha -> Smoothing Fucntion Parameter\n",
    "                   -That if number of W1 words under Class C1 is equal to 0, it'll make the entire P = 0, as its a product.\n",
    "                   - Also we are not ignoring the chances of this word even if it didn't occur, by giving it a less Prob.\n",
    "                   - Alpha should be small value, so that we are giving it a less Prob.\n",
    "                   - Dividing by Vocab to normailize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Transforming  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creating a Training Data Vocabulary (Fitting Vocab)\n",
    "\n",
    "2. Transforming 'Training Data' on Fitted Trainng Data Vocab\n",
    "\n",
    "3. Transforming 'Testing Data' on Fitted Trainng Data Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Creating a Training Data Vocabulary (Fitting Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (Train Data)= 6375 words\n"
     ]
    }
   ],
   "source": [
    "# This is a very crude and generalised way\n",
    "Vocab = sorted(list(set(' '.join(train_data.Processed_Document).split())))\n",
    "\n",
    "print \"Vocabulary (Train Data)= {} words\".format(len(Vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in Dataset = 7116 words\n"
     ]
    }
   ],
   "source": [
    "print \"Total Words in Dataset = {} words\".format(len(sorted(list(set(' '.join(df.Processed_Document).split())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transforming 'Training Data' on Fitted Trainng Data Vocab:- Building a Presence/Absence table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Word_Presence_Table = pd.DataFrame()\n",
    "\n",
    "for word in Vocab:\n",
    "    \n",
    "    presence_per_doc = []\n",
    "\n",
    "    for doc in train_data['Processed_Document']:\n",
    "        \n",
    "        if word in doc.split():\n",
    "            presence_per_doc.append(1)\n",
    "        else:\n",
    "            presence_per_doc.append(0)\n",
    "    \n",
    "    Word_Presence_Table[word] = presence_per_doc\n",
    "\n",
    "Word_Presence_Table['Class'] = train_data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abeg</th>\n",
       "      <th>abel</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>abi</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zyada</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aah  aaniye  aaooooright  aathi  ab  abeg  abel  aberdeen  abi  ...    \\\n",
       "0   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "1   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "2   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "3   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "4   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "\n",
       "   zebra  zed  zero  zf  zhong  zindgi  zoe  zoom  zyada  Class  \n",
       "0      0    0     0   0      0       0    0     0      0      0  \n",
       "1      0    0     0   0      0       0    0     0      0      1  \n",
       "2      0    0     0   0      0       0    0     0      0      1  \n",
       "3      0    0     0   0      0       0    0     0      0      0  \n",
       "4      0    0     0   0      0       0    0     0      0      0  \n",
       "\n",
       "[5 rows x 6376 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Presence_Table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 6376)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Presence_Table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No of columns = 6376 = 6375(Vocab Words) + 1(Class)\n",
    "\n",
    "- Columns = Vocab learned by Training Data = Total 6375 Words learned from Train Data. Will be used to fit on the test data as well\n",
    "\n",
    "- Represnts all the words in the Train Data along with their presence across all docs\n",
    "- Example, word 'aa' doesn't appear in first 5 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transforming 'Testing Data' on Fitted Trainng Data Vocab:- Building a Presence/Absence table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abeg</th>\n",
       "      <th>abel</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>abi</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aah  aaniye  aaooooright  aathi  ab  abeg  abel  aberdeen  abi  ...    \\\n",
       "0   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "1   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "2   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "3   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "4   0    0       0            0      0   0     0     0         0    0  ...     \n",
       "\n",
       "   zealand  zebra  zed  zero  zf  zhong  zindgi  zoe  zoom  zyada  \n",
       "0        0      0    0     0   0      0       0    0     0      0  \n",
       "1        0      0    0     0   0      0       0    0     0      0  \n",
       "2        0      0    0     0   0      0       0    0     0      0  \n",
       "3        0      0    0     0   0      0       0    0     0      0  \n",
       "4        0      0    0     0   0      0       0    0     0      0  \n",
       "\n",
       "[5 rows x 6375 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Word_Presence_Table = pd.DataFrame()\n",
    "\n",
    "for word in Vocab:\n",
    "    \n",
    "    presence_per_doc = []\n",
    "\n",
    "    for doc in test_data['Processed_Document']:\n",
    "        \n",
    "        if word in doc.split():\n",
    "            presence_per_doc.append(1)\n",
    "        else:\n",
    "            presence_per_doc.append(0)\n",
    "    \n",
    "    Test_Word_Presence_Table[word] = presence_per_doc\n",
    "    \n",
    "Test_Word_Presence_Table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Word_Presence_Table.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prob of a class: P(Class = C_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3850\n",
       "1     608\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_class(cls):\n",
    "    \n",
    "    N = len(train_data.Label)\n",
    "    Prob = train_data.Label.value_counts()[cls].astype(float)/N\n",
    "    return Prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prob of  a word given a particular class: P(Wordj |Class = C_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_word_given_class(word, cls, alpha):\n",
    "    \n",
    "    # For a word existing in our training data's Vocabulary\n",
    "    if word in Vocab:\n",
    "        Appearance = Word_Presence_Table[Word_Presence_Table['Class'] == cls][word].sum()\n",
    "        N = len(Word_Presence_Table[Word_Presence_Table['Class'] == cls])\n",
    "        Prob = (Appearance + alpha)/(N + len(Vocab))\n",
    "    \n",
    "    # For a new word only present in our test data (Real world scenario)\n",
    "    else:\n",
    "        Prob = (0 + alpha)/(N + len(Vocab))\n",
    "        \n",
    "    return Prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Class for individual test docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_class_with_test_feature_vector(test_doc_feature_vector):\n",
    "    \n",
    "    \n",
    "    # Vocab (Train Data) = [V1, V2, V3, ..., Vn-1, Vn]\n",
    "    #\n",
    "    # test_doc_feature_vector = [V1=1|0, V2=1|0, V3=1|0, ..., Vn-1=1|0, Vn=1|0] = [0,0,0, ..., 1, 0]\n",
    "    #\n",
    "    # Example: test_doc_feature_vector = [0,0,0, ..., 1,0]\n",
    "    #          \n",
    "    #  - It means, V1 is absent, V2 is absent, V3 is absent, ..., Vn-1 is present, Vn is absent\n",
    "    #  - P(V1,V2,V3...|Class=C1) = { [1- P(V1)] * [1- P(V2)] * [1- P(V3)] * ... * [P(Vn-1)] * [1 - P(Vn)] } x P(C1)\n",
    "    \n",
    "    global Vocab\n",
    "    \n",
    "    # Intilising \"big_class\" with a random choice\n",
    "    big = 0\n",
    "    big_class = random.choice(df.Label.unique())\n",
    "\n",
    "    # Smoothing Function Parameter \n",
    "    alpha = 0.0001\n",
    "\n",
    "    for cls in df.Label.unique():\n",
    "        \n",
    "        # For each class, \n",
    "        likelihood = 1\n",
    "        for word, word_vector in zip(Vocab, test_doc_feature_vector):\n",
    "\n",
    "            Prob_word = prob_word_given_class(word, cls, alpha)\n",
    "\n",
    "            if word_vector == 1:\n",
    "                likelihood *= Prob_word\n",
    "            else:\n",
    "                likelihood *= (1.0 - Prob_word)\n",
    "\n",
    "        likelihood *= prob_class(cls)\n",
    "\n",
    "        if likelihood > big:\n",
    "            big = likelihood\n",
    "            big_class = cls\n",
    "\n",
    "        \n",
    "    return big_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood: Prob of a unknown class given all words in the test data: P(Class=? | W1,W2,W3,W4...... Wj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat = []\n",
    "\n",
    "# Test_Word_Presence_Table.values = 2D Array of 1 or 0 values for each Vocab Word, 6375 Columns\n",
    "for test_doc_feature_vector in Test_Word_Presence_Table.values:\n",
    "\n",
    "    predicted_class = prob_class_with_test_feature_vector(test_doc_feature_vector)\n",
    "    Y_test_hat.append(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(len(test_data)):\n",
    "\n",
    "    if list(test_data.Label)[i] == Y_test_hat[i]:\n",
    "        score.append(100)\n",
    "    else:\n",
    "        score.append(0)\n",
    "        \n",
    "accuracy_matrix = pd.DataFrame({'Y_test': test_data.Label, \n",
    "                                'Y_test_hat (predicted)': Y_test_hat,\n",
    "                                'Score': score })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of model = 97.8456014363%\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy Score of model = {}%\".format(accuracy_matrix.Score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Using Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>Document</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4773</td>\n",
       "      <td>Hi..i got the money da:)</td>\n",
       "      <td>0</td>\n",
       "      <td>hi got money da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2981</td>\n",
       "      <td>Xmas Offer! Latest Motorola, SonyEricsson &amp; No...</td>\n",
       "      <td>1</td>\n",
       "      <td>xmas offer latest motorola sonyericsson nokia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4579</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>1</td>\n",
       "      <td>contract mobile mnths latest motorola nokia et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272</td>\n",
       "      <td>Sorry chikku, my cell got some problem thts y ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry chikku cell got problem thts nt able rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3747</td>\n",
       "      <td>Aight, let me know when you're gonna be around...</td>\n",
       "      <td>0</td>\n",
       "      <td>aight let know gonna around usf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_Number                                           Document  Label  \\\n",
       "0        4773                           Hi..i got the money da:)      0   \n",
       "1        2981  Xmas Offer! Latest Motorola, SonyEricsson & No...      1   \n",
       "2        4579  Had your contract mobile 11 Mnths? Latest Moto...      1   \n",
       "3        1272  Sorry chikku, my cell got some problem thts y ...      0   \n",
       "4        3747  Aight, let me know when you're gonna be around...      0   \n",
       "\n",
       "                                  Processed_Document  \n",
       "0                                    hi got money da  \n",
       "1  xmas offer latest motorola sonyericsson nokia ...  \n",
       "2  contract mobile mnths latest motorola nokia et...  \n",
       "3  sorry chikku cell got problem thts nt able rep...  \n",
       "4                    aight let know gonna around usf  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.Processed_Document\n",
    "Y = df.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457 4457\n",
      "1115 1115\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=0.80)\n",
    "\n",
    "print len(X_train), len(Y_train)\n",
    "print len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Converts text into a feature vector     Doc            (Term_doc) Hey   May   Be   -->  Feature Vector\n",
    "#                                     \"Hey may be\"                   1     1     1        [1,1,1]\n",
    "#                                     \" may be\"                      0     1     1        [0,1,1]\n",
    "#                                     \" hey hey may be be hey\"       3     1     2        [3,1,2]\n",
    "Vector = CountVectorizer()\n",
    "\n",
    "-> Vecotor.fit_transform()     : fits the data into vectors and then standardizes it.\n",
    "-> Vector.get_feature_names()  : tells about the features created (unique words) or is called a Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Train-data Vocab and vectorising train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab (Train Data) = 6279 words\n"
     ]
    }
   ],
   "source": [
    "Vector = CountVectorizer(binary=True)         # binary = True; Will check the presence or absence and put 1 or 0 only.\n",
    "\n",
    "Vector.fit(X_train)\n",
    "\n",
    "print 'Vocab (Train Data) = {} words'.format(len(Vector.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform our train data (Vectorising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (4457L, 6279L)\n"
     ]
    }
   ],
   "source": [
    "# Vector Standardized using transform()\n",
    "X_train_vector = Vector.transform(X_train)\n",
    "print \"Shape =\", X_train_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform test-data (using fitted vocabulary) into a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (1115L, 6279L)\n"
     ]
    }
   ],
   "source": [
    "# Using training data's Vocab (fitted on vector) to transform test sample\n",
    "X_test_vector = Vector.transform(X_test)\n",
    "print \"Shape =\", X_test_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Binary = True in CountVectorizer will limit the integer values to True(1) or False(0) only. Checking that by printing the train vector and finding the max value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vector.toarray().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = { 1, 0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Columns/Features should be same as we have used training-data's Vocab to transform test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = BernoulliNB(alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vector, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat = model.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.744394618834093"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_test_hat)*100.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
